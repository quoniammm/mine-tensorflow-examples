{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 167.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_epoch_stats(epoch_i, sess, last_features, last_labels):\n",
    "    \"\"\"\n",
    "    Print cost and validation accuracy of an epoch\n",
    "    \"\"\"\n",
    "    \n",
    "    current_cost = sess.run(\n",
    "        cost,\n",
    "        feed_dict={x: last_features, y: last_labels, keep_prob: 1.})\n",
    "    valid_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={x: last_features,y: last_labels, keep_prob: 1.})\n",
    "    print('Epoch: {} - Cost: {} Valid Accuracy: {}'.format(\n",
    "        epoch_i,\n",
    "        current_cost,\n",
    "        valid_accuracy))\n",
    "\n",
    "def normalize_grayscale(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    a = 0.1\n",
    "    b = 0.9\n",
    "    grayscale_min = 0\n",
    "    grayscale_max = 255\n",
    "    return a + ( ( (image_data - grayscale_min)*(b - a) )/( grayscale_max - grayscale_min ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# one-hot 编码\n",
    "train_d = train_data\n",
    "dummies = pd.get_dummies(train_data['label'], prefix='label', drop_first=False)\n",
    "train_features = train_d.drop('label', axis=1)\n",
    "train_labels = dummies\n",
    "train_data = pd.concat([train_labels, train_features], axis=1)\n",
    "\n",
    "train_features = np.reshape(np.array(normalize_grayscale(train_features)),(42000, 28, 28, 1))\n",
    "train_labels = np.array(train_labels)\n",
    "test_features = np.reshape(np.array(normalize_grayscale(test_data)),(28000, 28, 28, 1))\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 35000\n",
    "batch_size = 50\n",
    "# 用来验证和计算准确率的样本数\n",
    "# 如果内存不够，可以调小这个数字\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "# 神经网络参数\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.8  # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print(np.array(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, k, k, 1],\n",
    "        strides=[1, k, k, 1],\n",
    "        padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Layer 1 - 28*28*1 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    print(conv1.get_shape())\n",
    "\n",
    "    # Layer 2 - 14*14*32 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    print(conv2.get_shape())\n",
    "\n",
    "    # Fully connected layer - 7*7*64 to 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    print(fc1.get_shape())\n",
    "    \n",
    "\n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 14, 14, 32)\n",
      "(?, 7, 7, 64)\n",
      "(?, 1024)\n"
     ]
    }
   ],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000\n"
     ]
    }
   ],
   "source": [
    "print( train_features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "num_examples = train_features.shape[0]\n",
    "\n",
    "# serve data by batches\n",
    "def next_batch(batch_size):\n",
    "    \n",
    "    global train_features\n",
    "    global train_labels\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "#     print(index_in_epoch)\n",
    "    \n",
    "    # when all trainig data have been already used, it is reorder randomly    \n",
    "    if index_in_epoch > num_examples:\n",
    "#         print(\"weeeeeeee\")\n",
    "        # finished epoch\n",
    "        epochs_completed += 1\n",
    "        # shuffle the data\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "#         print(\"weeeeeeee2\")\n",
    "        train_features = train_features[perm]\n",
    "#         print(\"weeeeeeee3\")\n",
    "#         print(type(train_labels))\n",
    "#         print(train_labels.shape)\n",
    "#         print(train_features.shape)\n",
    "        \n",
    "#         print(perm)\n",
    "#         print(len(perm))\n",
    "        train_labels = train_labels[perm]\n",
    "        # start next epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= num_examples\n",
    "    end = index_in_epoch\n",
    "    return train_features[start:end], train_labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Cost: 67819.234375 Valid Accuracy: 0.09999999403953552\n",
      "Epoch: 500 - Cost: 1542.554931640625 Valid Accuracy: 0.8199999928474426\n",
      "Epoch: 1000 - Cost: 734.9008178710938 Valid Accuracy: 0.8999999761581421\n",
      "Epoch: 1500 - Cost: 379.24383544921875 Valid Accuracy: 0.9600000381469727\n",
      "Epoch: 2000 - Cost: 159.68606567382812 Valid Accuracy: 0.940000057220459\n",
      "Epoch: 2500 - Cost: 217.58084106445312 Valid Accuracy: 0.9599999785423279\n",
      "Epoch: 3000 - Cost: 192.2558135986328 Valid Accuracy: 0.9599999785423279\n",
      "Epoch: 3500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 4000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 4500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 5000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 5500 - Cost: 10.180459022521973 Valid Accuracy: 0.9800000190734863\n",
      "Epoch: 6000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 6500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 7000 - Cost: 66.54513549804688 Valid Accuracy: 0.9799999594688416\n",
      "Epoch: 7500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 8000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 8500 - Cost: 33.628536224365234 Valid Accuracy: 0.9799999594688416\n",
      "Epoch: 9000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 9500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 10000 - Cost: 31.990507125854492 Valid Accuracy: 0.9800000190734863\n",
      "Epoch: 10500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 11000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 11500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 12000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 12500 - Cost: 45.425193786621094 Valid Accuracy: 0.9800000190734863\n",
      "Epoch: 13000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 13500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 14000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 14500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 15000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 15500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 16000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 16500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 17000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 17500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 18000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 18500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 19000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 19500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 20000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 20500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 21000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 21500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 22000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 22500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 23000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 23500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 24000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 24500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 25000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 25500 - Cost: 44.77549743652344 Valid Accuracy: 0.9799999594688416\n",
      "Epoch: 26000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 26500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 27000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 27500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 28000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 28500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 29000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 29500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 30000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 30500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 31000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 31500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 32000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 32500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 33000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 33500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 34000 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "Epoch: 34500 - Cost: 0.0 Valid Accuracy: 1.0\n",
      "(28000, 10)\n",
      "       ImageId  Label\n",
      "0            1      2\n",
      "1            2      0\n",
      "2            3      9\n",
      "3            4      9\n",
      "4            5      3\n",
      "5            6      7\n",
      "6            7      0\n",
      "7            8      3\n",
      "8            9      0\n",
      "9           10      3\n",
      "10          11      5\n",
      "11          12      7\n",
      "12          13      4\n",
      "13          14      0\n",
      "14          15      4\n",
      "15          16      3\n",
      "16          17      3\n",
      "17          18      1\n",
      "18          19      9\n",
      "19          20      0\n",
      "20          21      9\n",
      "21          22      1\n",
      "22          23      1\n",
      "23          24      5\n",
      "24          25      7\n",
      "25          26      4\n",
      "26          27      2\n",
      "27          28      7\n",
      "28          29      4\n",
      "29          30      7\n",
      "...        ...    ...\n",
      "27970    27971      5\n",
      "27971    27972      0\n",
      "27972    27973      4\n",
      "27973    27974      8\n",
      "27974    27975      0\n",
      "27975    27976      3\n",
      "27976    27977      6\n",
      "27977    27978      0\n",
      "27978    27979      1\n",
      "27979    27980      9\n",
      "27980    27981      3\n",
      "27981    27982      1\n",
      "27982    27983      1\n",
      "27983    27984      0\n",
      "27984    27985      4\n",
      "27985    27986      5\n",
      "27986    27987      2\n",
      "27987    27988      2\n",
      "27988    27989      9\n",
      "27989    27990      6\n",
      "27990    27991      7\n",
      "27991    27992      6\n",
      "27992    27993      1\n",
      "27993    27994      9\n",
      "27994    27995      7\n",
      "27995    27996      9\n",
      "27996    27997      7\n",
      "27997    27998      3\n",
      "27998    27999      9\n",
      "27999    28000      2\n",
      "\n",
      "[28000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "init = tf.global_variables_initializer()\n",
    "# writer = tf.summary.FileWriter('./board')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        # for i in range(total_batch):\n",
    "        batch_x, batch_y = next_batch(batch_size)\n",
    "#         print(batch_x.shape)\n",
    "#         print(batch_y.shape)\n",
    "        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "        #print( sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.}))\n",
    "        if(epoch % 500 == 0):\n",
    "            print_epoch_stats(epoch, sess, batch_x, batch_y)\n",
    "    \n",
    "    conv_y_predict = []\n",
    "    for i in np.arange(100, 280001, 100):\n",
    "        conv_y_predict = np.append(conv_y_predict, np.array(sess.run(logits, feed_dict = {x: test_features[i-100:i], keep_prob: 1.})))\n",
    "#         print(sess.run(logits, feed_dict = {x: test_features[i-100:i], keep_prob: 1.}))\n",
    "#         conv_y_predict += np.array(sess.run(logits, feed_dict = {x: test_features[i-100:i], keep_prob: 1.}))\n",
    "\n",
    "    conv_y_predict = np.reshape(np.array(conv_y_predict),(28000, 10))\n",
    "    print(conv_y_predict.shape)\n",
    "    \n",
    "    test_pre = np.argmax(conv_y_predict, 1)\n",
    "    \n",
    "    conv_y_submission = pd.DataFrame({\n",
    "        'ImageId': range(1, 28001), \n",
    "        'Label': test_pre \n",
    "    })\n",
    "\n",
    "    conv_y_submission.head()\n",
    "    print(conv_y_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "conv_y_submission.to_csv('./conv_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
