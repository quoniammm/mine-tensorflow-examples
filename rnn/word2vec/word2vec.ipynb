{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用 tensorflow 实现 word2vec\n",
    "\n",
    "import tensorflow as tf\n",
    "import process_data\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集已经存在于: ./data/text8.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./data/text8.zip'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据探索\n",
    "DOWNLOAD_URL = 'http://mattmahoney.net/dc/'\n",
    "EXPECTED_BYTES = 31344016\n",
    "DATA_FOLDER = './data/'\n",
    "FILE_NAME = 'text8.zip'\n",
    "\n",
    "## parameters\n",
    "VOCAB_SIZE = 50000\n",
    "BATCH_SIZE = 128\n",
    "EMBED_SIZE = 128 # dimension of the word embedding vectors\n",
    "SKIP_WINDOW = 1 # the context window\n",
    "NUM_SAMPLED = 64    # Number of negative examples to sample.\n",
    "LEARNING_RATE = 1.0\n",
    "NUM_TRAIN_STEPS = 10000\n",
    "SKIP_STEP = 2000 # how many steps to skip before reporting the loss\n",
    "\n",
    "process_data.download(FILE_NAME, EXPECTED_BYTES, DATA_FOLDER, DOWNLOAD_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philosophy is the belief that rulers are unnecessary and should be abolished although there are differing interpretations of what this means anarchism also refers to related social movements that advocate the elimination of authoritarian institutions particularly the state the word anarchy as most anarchists use it does not imply chaos nihilism or anomie but rather a harmonious anti authoritarian society in place of what are regarded as authoritarian political structures and coercive economic instituti\n"
     ]
    }
   ],
   "source": [
    "words = process_data.read_data(DATA_FOLDER + FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17005207"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_to_int, int_to_vocab = process_data.build_vocab(words, VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_vocab = [vocab_to_int[word] if word in vocab_to_int else 0 for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object generate_sample at 0x7f58bd39c308>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_sample(index_words, context_window_size):\n",
    "    \"\"\" Form training pairs according to the skip-gram model. \"\"\"\n",
    "    for index, center in enumerate(index_words):\n",
    "        context = random.randint(1, context_window_size)\n",
    "        # get a random target before the center word\n",
    "        for target in index_words[max(0, index - context): index]:\n",
    "            yield center, target\n",
    "        # get a random target after the center wrod\n",
    "        for target in index_words[index + 1: index + context + 1]:\n",
    "            yield center, target\n",
    "            \n",
    "            \n",
    "single_gen = generate_sample(int_vocab, SKIP_WINDOW)\n",
    "single_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object get_batch at 0x7f58bd39cba0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_batch(iterator, batch_size):\n",
    "    \"\"\" Group a numerical stream into batches and yield them as Numpy arrays. \"\"\"\n",
    "    while True:\n",
    "        center_batch = np.zeros(batch_size, dtype=np.int32)\n",
    "        target_batch = np.zeros([batch_size, 1])\n",
    "        for index in range(batch_size):\n",
    "            center_batch[index], target_batch[index] = next(iterator)\n",
    "        yield center_batch, target_batch\n",
    "        \n",
    "batch_gen = get_batch(single_gen, BATCH_SIZE)\n",
    "batch_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义图(Graph)\n",
    "\n",
    "## 1.定义输入和输出\n",
    "with tf.name_scope('data'):\n",
    "    center_words = tf.placeholder(tf.int32, shape=[BATCH_SIZE], name='center_words')\n",
    "    target_words = tf.placeholder(tf.int32, shape=[BATCH_SIZE, 1], name='target_words')\n",
    "\n",
    "## 2.定义权重\n",
    "with tf.name_scope('embedding_matrix'):\n",
    "    embed_matrix = tf.Variable(tf.random_normal([VOCAB_SIZE, BATCH_SIZE], -1.0, 1.0), name='embed_matrix')\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    ## 3.实现 embedding_lookup()\n",
    "    embed = tf.nn.embedding_lookup(embed_matrix, center_words)\n",
    "\n",
    "    ## 4.定义 LOSS 函数\n",
    "\n",
    "    ### 4.1 定义 weights 和 bias 使得隐藏层可以计算 NCE loss\n",
    "    nce_weight = tf.Variable(tf.truncated_normal([VOCAB_SIZE, EMBED_SIZE], stddev=1.0 / EMBED_SIZE ** 0.5))\n",
    "    nce_bias = tf.Variable(tf.zeros([VOCAB_SIZE]))\n",
    "\n",
    "    ### 4.2 实现 nce_loss\n",
    "    loss = tf.reduce_mean(tf.nn.nce_loss(\n",
    "        weights = nce_weight,\n",
    "        biases = nce_bias,\n",
    "        labels = target_words,\n",
    "        inputs = embed,\n",
    "        num_sampled = NUM_SAMPLED,\n",
    "        num_classes = VOCAB_SIZE\n",
    "    ))\n",
    "\n",
    "## 5.定义优化器\n",
    "optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 1999: 121.4\n",
      "Average loss at step 3999:  66.5\n",
      "Average loss at step 5999:  38.3\n",
      "Average loss at step 7999:  26.9\n",
      "Average loss at step 9999:  20.4\n"
     ]
    }
   ],
   "source": [
    "# 在 SESSION 中计算图（运行模型）\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    writer = tf.summary.FileWriter('./data/no_frills/', sess.graph)\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for index in range(NUM_TRAIN_STEPS):\n",
    "            centers, targets = next(batch_gen)\n",
    "            loss_batch, _ = sess.run([loss, optimizer], \n",
    "                                    feed_dict={center_words: centers, target_words: targets})\n",
    "            total_loss += loss_batch\n",
    "            if (index + 1) % SKIP_STEP == 0:\n",
    "                print('Average loss at step {}: {:5.1f}'.format(index, total_loss / SKIP_STEP))\n",
    "                total_loss = 0.0\n",
    "    \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
